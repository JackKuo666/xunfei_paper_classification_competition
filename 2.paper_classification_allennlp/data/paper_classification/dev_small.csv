train_06284	P2D: a self-supervised method for depth estimation from polarimetry	  Monocular depth estimation is a recurring subject in the field of computervision. Its ability to describe scenes via a depth map while reducing theconstraints related to the formulation of perspective geometry tends to favorits use. However, despite the constant improvement of algorithms, most methodsexploit only colorimetric information. Consequently, robustness to events towhich the modality is not sensitive to, like specularity or transparency, isneglected. In response to this phenomenon, we propose using polarimetry as aninput for a self-supervised monodepth network. Therefore, we propose exploitingpolarization cues to encourage accurate reconstruction of scenes. Furthermore,we include a term of polarimetric regularization to state-of-the-art method totake specific advantage of the data. Our method is evaluated both qualitativelyand quantitatively demonstrating that the contribution of this new informationas well as an enhanced loss function improves depth estimation results,especially for specular areas.	cs.CV
train_20485	Considerations on Quantum-Based Methods for Communication Security	  In this paper we provide an intuitive-level discussion of the challenges andopportunities offered by quantum-based methods for supporting securecommunications, e.g., over a network. The goal is to distill down to the mostfundamental issues and concepts in order to provide a clear foundation forassessing the potential value of quantum-based technologies relative toclassical alternatives. It is hoped that this form of exposition can providegreater clarity of perspective than is typically offered bymathematically-focused treatments of the topic. It is also hoped that thisclarity extends to more general applications of quantum information sciencesuch as quantum computing and quantum sensing.	cs.CR
train_19283	Applying Type Oriented Programming to the PGAS Memory Model	  The Partitioned Global Address Space memory model has been popularised by anumber of languages and applications. However this abstraction can often resultin the programmer having to rely on some in built choices and with thisimplicit parallelism, with little assistance by the programmer, the scalabilityand performance of the code heavily depends on the compiler and choice ofapplication.  We propose an approach, type oriented programming, where all aspects ofparallelism are encoded via types and the type system. The type informationassociated by the programmer will determine, for instance, how an array isallocated, partitioned and distributed. With this rich, high level ofinformation the compiler can generate an efficient target executable. If theprogrammer wishes to omit detailed type information then the compiler will relyon well documented and safe default behaviour which can be tuned at a laterdate with the addition of types.  The type oriented parallel programming language Mesham, which follows thePGAS memory model, is presented. We illustrate how, if so wished, with the useof types one can tune all parameters and options associated with this PGASmodel in a clean and consistent manner without rewriting large portions ofcode. An FFT case study is presented and considered both in terms ofprogrammability and performance - the latter we demonstrate by a comparisonwith an existing FFT solver.	cs.PL
train_28239	Who Killed My Parked Car?	  We find that the conventional belief of vehicle cyber attacks and theirdefenses---attacks are feasible and thus defenses are required only when thevehicle's ignition is turned on---does not hold. We verify this fact bydiscovering and applying two new practical and important attacks: battery-drainand Denial-of-Body-control (DoB). The former can drain the vehicle batterywhile the latter can prevent the owner from starting or even opening/enteringhis car, when either or both attacks are mounted with the ignition off. Wefirst analyze how operation (e.g., normal, sleep, listen) modes of ECUs aredefined in various in-vehicle network standards and how they are implemented inthe real world. From this analysis, we discover that an adversary can exploitthe wakeup function of in-vehicle networks---which was originally designed forenhanced user experience/convenience (e.g., remote diagnosis, remotetemperature control)---as an attack vector. Ironically, a core battery-savingfeature in in-vehicle networks makes it easier for an attacker to wake up ECUsand, therefore, mount and succeed in battery-drain and/or DoB attacks. Viaextensive experimental evaluations on various real vehicles, we show that bymounting the battery-drain attack, the adversary can increase the averagebattery consumption by at least 12.57x, drain the car battery within a fewhours or days, and therefore immobilize/cripple the vehicle. We alsodemonstrate the proposed DoB attack on a real vehicle, showing that theattacker can cut off communications between the vehicle and the driver's keyfob by indefinitely shutting down an ECU, thus making the driver unable tostart and/or even enter the car.	cs.CR
train_31053	DARTS: Dialectal Arabic Transcription System	  We present the speech to text transcription system, called DARTS, for lowresource Egyptian Arabic dialect. We analyze the following; transfer learningfrom high resource broadcast domain to low-resource dialectal domain andsemi-supervised learning where we use in-domain unlabeled audio data collectedfrom YouTube. Key features of our system are: A deep neural network acousticmodel that consists of a front end Convolutional Neural Network (CNN) followedby several layers of Time Delayed Neural Network (TDNN) and Long-Short TermMemory Recurrent Neural Network (LSTM); sequence discriminative training of theacoustic model; n-gram and recurrent neural network language model for decodingand N-best list rescoring. We show that a simple transfer learning method canachieve good results. The results are further improved by using unlabeled datafrom YouTube in a semi-supervised setup. Various systems are combined to givethe final system that achieves the lowest word error on on the communitystandard Egyptian-Arabic speech dataset (MGB-3).	cs.CL
train_37642	Face Recognition using 3D Facial Shape and Color Map Information:  Comparison and Combination	  In this paper, we investigate the use of 3D surface geometry for facerecognition and compare it to one based on color map information. The 3Dsurface and color map data are from the CAESAR anthropometric database. We findthat the recognition performance is not very different between 3D surface andcolor map information using a principal component analysis algorithm. We alsodiscuss the different techniques for the combination of the 3D surface andcolor map information for multi-modal recognition by using different fusionapproaches and show that there is significant improvement in results. Theeffectiveness of various techniques is compared and evaluated on a dataset with200 subjects in two different positions.	cs.CV
train_18185	Generalized Centrality Aggregation and Exclusive Centrality	  There are several applications that benefit from a definition of centralitywhich is applicable to sets of vertices, rather than individual vertices.However, existing definitions might not be able to help us in answering severalnetwork analysis questions. In this paper, we study generalizing aggregation ofcentralities of individual vertices, to the centrality of the set consisting ofthese vertices. In particular, we propose exclusive betweenness centrality,defined as the number of shortest paths passing over exactly one of thevertices in the set, and discuss how this can be useful in determining theproper center of a network. We mathematically formulate the relationshipbetween exclusive betweenness centrality and the existing notions of setcentrality, and use this relation to present an exact algorithm for computingexclusive betweenness centrality. Since it is usually practically intractableto compute exact centrality scores for large real-world networks, we alsopresent approximate algorithms for estimating exclusive betweenness centrality.In the end, we evaluate the empirical efficiency of exclusive betweennesscentrality computation over several real-world networks. Moreover, weempirically study the correlations between exclusive betweenness centrality andthe existing set centrality notions.	cs.SI
train_32518	Synthesising Wider Field Images from Narrow-Field Retinal Video Acquired  Using a Low-Cost Direct Ophthalmoscope (Arclight) Attached to a Smartphone	  Access to low cost retinal imaging devices in low and middle income countriesis limited, compromising progress in preventing needless blindness. TheArclight is a recently developed low-cost solar powered direct ophthalmoscopewhich can be attached to the camera of a smartphone to acquire retinal imagesand video. However, the acquired data is inherently limited by the optics ofdirect ophthalmoscopy, resulting in a narrow field of view with associatedcorneal reflections, limiting its usefulness. In this work we describe thefirst fully automatic method utilizing videos acquired using the Arclightattached to a mobile phone camera to create wider view, higher quality stillimages comparable with images obtained using much more expensive and bulkydedicated traditional retinal cameras.	cs.CV
train_06391	Applying Spiking Neural Nets to Noise Shaping	  -In recent years, there has been an increased focus on the mechanics ofinformation transmission in spiking neural networks. Especially the NoiseShaping properties of these networks and their similarity to Delta-SigmaModulators has received a lot of attention. However, very little of theresearch done in this area has focused on the effect the weights in thesenetworks have on the Noise Shaping properties and on post- processing of thenetwork output signal. This paper concerns itself with the various modes ofnetwork operation and beneficial as well as detrimental effects which thesystematic generation of network weights can effect. Also, a method forpost-processing of the spiking output signal is introduced, bringing the outputsignal more in line with conventional Delta-Sigma Modulators. Relevancy of thisresearch to industrial application of neural nets as building blocks ofoversampled A/D converters is shown. Also, further points of contention arelisted, which must be thoroughly researched to add to the above mentionedapplicability of spiking neural nets.	cs.ET
train_25539	Unsupervised Image-to-Image Translation Using Domain-Specific  Variational Information Bound	  Unsupervised image-to-image translation is a class of computer visionproblems which aims at modeling conditional distribution of images in thetarget domain, given a set of unpaired images in the source and target domains.An image in the source domain might have multiple representations in the targetdomain. Therefore, ambiguity in modeling of the conditional distributionarises, specially when the images in the source and target domains come fromdifferent modalities. Current approaches mostly rely on simplifying assumptionsto map both domains into a shared-latent space. Consequently, they are onlyable to model the domain-invariant information between the two modalities.These approaches usually fail to model domain-specific information which has norepresentation in the target domain. In this work, we propose an unsupervisedimage-to-image translation framework which maximizes a domain-specificvariational information bound and learns the target domain-invariantrepresentation of the two domain. The proposed framework makes it possible tomap a single source image into multiple images in the target domain, utilizingseveral target domain-specific codes sampled randomly from the priordistribution, or extracted from reference images.	cs.CV
train_41311	360SD-Net: 360{\deg} Stereo Depth Estimation with Learnable Cost Volume	  Recently, end-to-end trainable deep neural networks have significantlyimproved stereo depth estimation for perspective images. However, 360{\deg}images captured under equirectangular projection cannot benefit from directlyadopting existing methods due to distortion introduced (i.e., lines in 3D arenot projected onto lines in 2D). To tackle this issue, we present a novelarchitecture specifically designed for spherical disparity using the setting oftop-bottom 360{\deg} camera pairs. Moreover, we propose to mitigate thedistortion issue by (1) an additional input branch capturing the position andrelation of each pixel in the spherical coordinate, and (2) a cost volume builtupon a learnable shifting filter. Due to the lack of 360{\deg} stereo data, wecollect two 360{\deg} stereo datasets from Matterport3D and Stanford3D fortraining and evaluation. Extensive experiments and ablation study are providedto validate our method against existing algorithms. Finally, we show promisingresults on real-world environments capturing images with two consumer-levelcameras.	cs.CV
train_07655	Generalizing Jeffrey Conditionalization	  Jeffrey's rule has been generalized by Wagner to the case in which newevidence bounds the possible revisions of a prior probability below by aDempsterian lower probability. Classical probability kinematics arises withinthis generalization as the special case in which the evidentiary focal elementsof the bounding lower probability are pairwise disjoint. We discuss a twofoldextension of this generalization, first allowing the lower bound to be anytwo-monotone capacity and then allowing the prior to be a lower envelope.	cs.AI
train_00985	Breaking the Bound: Rate-2, Full Diversity, Orthogonal MIMO-STBC  Transceiver Design	  Space Time Block Codes (STBCs) from orthogonal designs have attractedsignificant interest in recent years. However, with the growing demand forhigher capacity schemes, the multiantenna transmission techniques must supportand achieve higher symbol transmission rates. In this article, we focus onthree and four transmit antenna schemes. For over two decades, STBC schemes forthree and four transmit antennas that achieve a very high symbol transmissionrate while being orthogonal, fully diverse, delay-efficient, and with very lowdecoding complexity have not been achieved. The schemes proposed so far tradesoff orthogonality, delay, diversity, or decoding complexity while achievingrate or vice-versa. This work is first of its kind to solve this problem whilefulfilling all the desired properties.  In this work, we carefully study the various aspects that must be consideredin designing higher symbol transmission rate STBCs. The proposed designs,hereby referred to as, Jagannath schemes - for 4 x 3 and 4 x 4 configurationsare orthogonal, achieve full diversity, and support a symbol transmission rateof 2 symbols/s/Hz. The design methodology follows a coding gain maximizationapproach. The low decoding complexity procedure to decode the proposedtransmission schemes are proposed as well as extensively evaluated insimulations under diverse settings. The performance of proposed schemes areempirically compared to two state-of-the-art schemes; ACIOD and Jafarkhani.Jagannath 4 x 3 was shown to outperform ACIOD by ~12 dB while Jagannath 4 x 4exhibited a ~7 dB superior performance in contrast to Jafarkhani at 4 bpcu.This motivates the adoption of Jagannath schemes in tactical and commercialcommunication systems to effectively double the throughput or to extend the	cs.NI
train_32260	A Canonical Model Construction for Iteration-Free PDL with Intersection	  We study the axiomatisability of the iteration-free fragment of PropositionalDynamic Logic with Intersection and Tests. The combination of programcomposition, intersection and tests makes its proof-theory rather difficult. Wedevelop a normal form for formulae which minimises the interaction betweenthese operators, as well as a refined canonical model construction. From thesewe derive an axiom system and a proof of its strong completeness.	cs.LO
train_47344	Algorithmic linear dimension reduction in the l_1 norm for sparse  vectors	  This paper develops a new method for recovering m-sparse signals that issimultaneously uniform and quick. We present a reconstruction algorithm whoserun time, O(m log^2(m) log^2(d)), is sublinear in the length d of the signal.The reconstruction error is within a logarithmic factor (in m) of the optimalm-term approximation error in l_1. In particular, the algorithm recoversm-sparse signals perfectly and noisy signals are recovered with polylogarithmicdistortion. Our algorithm makes O(m log^2 (d)) measurements, which is within alogarithmic factor of optimal. We also present a small-space implementation ofthe algorithm. These sketching techniques and the corresponding reconstructionalgorithms provide an algorithmic dimension reduction in the l_1 norm. Inparticular, vectors of support m in dimension d can be linearly embedded intoO(m log^2 d) dimensions with polylogarithmic distortion. We can reconstruct avector from its low-dimensional sketch in time O(m log^2(m) log^2(d)).Furthermore, this reconstruction is stable and robust under smallperturbations.	cs.DS
train_28618	Replicability Analysis for Natural Language Processing: Testing  Significance with Multiple Datasets	  With the ever-growing amounts of textual data from a large variety oflanguages, domains, and genres, it has become standard to evaluate NLPalgorithms on multiple datasets in order to ensure consistent performanceacross heterogeneous setups. However, such multiple comparisons posesignificant challenges to traditional statistical analysis methods in NLP andcan lead to erroneous conclusions. In this paper, we propose a ReplicabilityAnalysis framework for a statistically sound analysis of multiple comparisonsbetween algorithms for NLP tasks. We discuss the theoretical advantages of thisframework over the current, statistically unjustified, practice in the NLPliterature, and demonstrate its empirical value across four applications:multi-domain dependency parsing, multilingual POS tagging, cross-domainsentiment classification and word similarity prediction.	cs.CL
train_00218	Cooperative Inverse Reinforcement Learning	  For an autonomous system to be helpful to humans and to pose no unwarrantedrisks, it needs to align its values with those of the humans in its environmentin such a way that its actions contribute to the maximization of value for thehumans. We propose a formal definition of the value alignment problem ascooperative inverse reinforcement learning (CIRL). A CIRL problem is acooperative, partial-information game with two agents, human and robot; bothare rewarded according to the human's reward function, but the robot does notinitially know what this is. In contrast to classical IRL, where the human isassumed to act optimally in isolation, optimal CIRL solutions produce behaviorssuch as active teaching, active learning, and communicative actions that aremore effective in achieving value alignment. We show that computing optimaljoint policies in CIRL games can be reduced to solving a POMDP, prove thatoptimality in isolation is suboptimal in CIRL, and derive an approximate CIRLalgorithm.	cs.AI
train_13488	Bayesian Surface Warping Approach For Rectifying Geological Boundaries  Using Displacement Likelihood And Evidence From Geochemical Assays	  This paper presents a Bayesian framework for manipulating mesh surfaces withthe aim of improving the positional integrity of the geological boundaries thatthey seek to represent. The assumption is that these surfaces, createdinitially using sparse data, capture the global trend and provide a reasonableapproximation of the stratigraphic, mineralisation and other types ofboundaries for mining exploration, but they are locally inaccurate at scalestypically required for grade estimation. The proposed methodology makes localspatial corrections automatically to maximise the agreement between themodelled surfaces and observed samples. Where possible, vertices on a meshsurface are moved to provide a clear delineation, for instance, between ore andwaste material across the boundary based on spatial and compositional analysis;using assay measurements collected from densely spaced, geo-registered blastholes. The maximum a posteriori (MAP) solution ultimately considers thechemistry observation likelihood in a given domain. Furthermore, it is guidedby an apriori spatial structure which embeds geological domain knowledge anddetermines the likelihood of a displacement estimate. The results demonstratethat increasing surface fidelity can significantly improve grade estimationperformance based on large-scale model validation.	cs.CE
train_49778	Convex Independence in Permutation Graphs	  A set C of vertices of a graph is P_3-convex if every vertex outside C has atmost one neighbor in C. The convex hull \sigma(A) of a set A is the smallestP_3-convex set that contains A. A set M is convexly independent if for everyvertex x \in M, x \notin \sigma(M-x). We show that the maximal number ofvertices that a convexly independent set in a permutation graph can have, canbe computed in polynomial time.	cs.DM
train_23986	Symbolic Dynamic Programming for Discrete and Continuous State MDPs	  Many real-world decision-theoretic planning problems can be naturally modeledwith discrete and continuous state Markov decision processes (DC-MDPs). Whileprevious work has addressed automated decision-theoretic planning for DCMDPs,optimal solutions have only been defined so far for limited settings, e.g.,DC-MDPs having hyper-rectangular piecewise linear value functions. In thiswork, we extend symbolic dynamic programming (SDP) techniques to provideoptimal solutions for a vastly expanded class of DCMDPs. To address theinherent combinatorial aspects of SDP, we introduce the XADD - a continuousvariable extension of the algebraic decision diagram (ADD) - that maintainscompact representations of the exact value function. Empirically, wedemonstrate an implementation of SDP with XADDs on various DC-MDPs, showing thefirst optimal automated solutions to DCMDPs with linear and nonlinear piecewisepartitioned value functions and showing the advantages of constraint-basedpruning for XADDs.	cs.AI
train_15285	Implementation of Handoff through wireless access point Techniques	  Handoff has become an inevitable part of wireless cellular communication,Soon users will carry small portable handheld devices which will incorporatethe computer, phone, camera, GPS, personal control module etc. This paperproposes a new scheme to deal with seam less roaming and reduce failedhandoffs. The simulation is done using software called Qualnet meant forwireless communication. The results clearly indicate the advantages of this newscheme.	cs.NI
train_43786	HoVer-Net: Simultaneous Segmentation and Classification of Nuclei in  Multi-Tissue Histology Images	  Nuclear segmentation and classification within Haematoxylin & Eosin stainedhistology images is a fundamental prerequisite in the digital pathologywork-flow. The development of automated methods for nuclear segmentation andclassification enables the quantitative analysis of tens of thousands of nucleiwithin a whole-slide pathology image, opening up possibilities of furtheranalysis of large-scale nuclear morphometry. However, automated nuclearsegmentation and classification is faced with a major challenge in that thereare several different types of nuclei, some of them exhibiting largeintra-class variability such as the tumour cells. Additionally, some of thenuclei are often clustered together. To address these challenges, we present anovel convolutional neural network for simultaneous nuclear segmentation andclassification that leverages the instance-rich information encoded within thevertical and horizontal distances of nuclear pixels to their centres of mass.These distances are then utilised to separate clustered nuclei, resulting in anaccurate segmentation, particularly in areas with overlapping instances. Thenfor each segmented instance, the network predicts the type of nucleus via adevoted up-sampling branch. We demonstrate state-of-the-art performancecompared to other methods on multiple independent multi-tissue histology imagedatasets. As part of this work, we introduce a new dataset of Haematoxylin &Eosin stained colorectal adenocarcinoma image tiles, containing 24,319exhaustively annotated nuclei with associated class labels.	cs.CV
train_12482	Massively-Parallel Break Detection for Satellite Data	  The field of remote sensing is nowadays faced with huge amounts of data.While this offers a variety of exciting research opportunities, it also yieldssignificant challenges regarding both computation time and space requirements.In practice, the sheer data volumes render existing approaches too slow forprocessing and analyzing all the available data. This work aims at acceleratingBFAST, one of the state-of-the-art methods for break detection given satelliteimage time series. In particular, we propose a massively-parallelimplementation for BFAST that can effectively make use of modern parallelcompute devices such as GPUs. Our experimental evaluation shows that theproposed GPU implementation is up to four orders of magnitude faster than theexisting publicly available implementation and up to ten times faster than acorresponding multi-threaded CPU execution. The dramatic decrease in runningtime renders the analysis of significantly larger datasets possible in secondsor minutes instead of hours or days. We demonstrate the practical benefits ofour implementations given both artificial and real datasets.	cs.DC
train_47964	Train, Diagnose and Fix: Interpretable Approach for Fine-grained Action  Recognition	  Despite the growing discriminative capabilities of modern deep learningmethods for recognition tasks, the inner workings of the state-of-art modelsstill remain mostly black-boxes. In this paper, we propose a systematicinterpretation of model parameters and hidden representations of ResidualTemporal Convolutional Networks (Res-TCN) for action recognition in time-seriesdata. We also propose a Feature Map Decoder as part of the interpretationanalysis, which outputs a representation of model's hidden variables in thesame domain as the input. Such analysis empowers us to expose model'scharacteristic learning patterns in an interpretable way. For example, throughthe diagnosis analysis, we discovered that our model has learned to achieveview-point invariance by implicitly learning to perform rotationalnormalization of the input to a more discriminative view. Based on the findingsfrom the model interpretation analysis, we propose a targeted refinementtechnique, which can generalize to various other recognition models. Theproposed work introduces a three-stage paradigm for model learning: training,interpretable diagnosis and targeted refinement. We validate our approach onskeleton based 3D human action recognition benchmark of NTU RGB+D. We show thatthe proposed workflow is an effective model learning strategy and the resultingMulti-stream Residual Temporal Convolutional Network (MS-Res-TCN) achieves thestate-of-the-art performance on NTU RGB+D.	cs.CV
train_03661	Lights, Camera, Action! Exploring Effects of Visual Distractions on  Completion of Security Tasks	  Human errors in performing security-critical tasks are typically blamed onthe complexity of those tasks. However, such errors can also occur because of(possibly unexpected) sensory distractions. A sensory distraction that producesnegative effects can be abused by the adversary that controls the environment.Meanwhile, a distraction with positive effects can be artificially introducedto improve user performance.  The goal of this work is to explore the effects of visual stimuli on theperformance of security-critical tasks. To this end, we experimented with alarge number of subjects who were exposed to a range of unexpected visualstimuli while attempting to perform Bluetooth Pairing. Our results clearlydemonstrate substantially increased task completion times and markedly lowertask success rates. These negative effects are noteworthy, especially, whencontrasted with prior results on audio distractions which had positive effectson performance of similar tasks. Experiments were conducted in a novel (fullyautomated and completely unattended) experimental environment. This yieldedmore uniform experiments, better scalability and significantly lower financialand logistical burdens. We discuss this experience, including benefits andlimitations of the unattended automated experiment paradigm.	cs.HC
