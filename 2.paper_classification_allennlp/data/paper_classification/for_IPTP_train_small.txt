Hard but Robust, Easy but Sensitive: How Encoder and Decoder Perform in  Neural Machine Translation.  Neural machine translation (NMT) typically adopts the encoder-decoderframework. A good understanding of the characteristics and functionalities ofthe encoder and decoder can help to explain the pros and cons of the framework,and design better models for NMT. In this work, we conduct an empirical studyon the encoder and the decoder in NMT, taking Transformer as an example. Wefind that 1) the decoder handles an easier task than the encoder in NMT, 2) thedecoder is more sensitive to the input noise than the encoder, and 3) thepreceding words/tokens in the decoder provide strong conditional information,which accounts for the two observations above. We hope those observations canshed light on the characteristics of the encoder and decoder and inspire futureresearch on NMT.
An Easy-to-use Real-world Multi-objective Optimization Problem Suite.  Although synthetic test problems are widely used for the performanceassessment of evolutionary multi-objective optimization algorithms, they arelikely to include unrealistic properties which may lead tooverestimation/underestimation. To address this issue, we present amulti-objective optimization problem suite consisting of 16 bound-constrainedreal-world problems. The problem suite includes various problems in terms ofthe number of objectives, the shape of the Pareto front, and the type of designvariables. 4 out of the 16 problems are multi-objective mixed-integeroptimization problems. We provide Java, C, and Matlab source codes of the 16problems so that they are available in an off-the-shelf manner. We examine anapproximated Pareto front of each test problem. We also analyze the performanceof six representative evolutionary multi-objective optimization algorithms onthe 16 problems. In addition to the 16 problems, we present 8 constrainedmulti-objective real-world problems.
Exploration of reproducibility issues in scientometric research Part 1:  Direct reproducibility.  This is the first part of a small-scale explorative study in an effort tostart assessing reproducibility issues specific to scientometrics research.This effort is motivated by the desire to generate empirical data to informdebates about reproducibility in scientometrics. Rather than attempt toreproduce studies, we explore how we might assess "in principle"reproducibility based on a critical review of the content of published papers.The first part of the study focuses on direct reproducibility - that is theability to reproduce the specific evidence produced by an original study usingthe same data, methods, and procedures. The second part (Velden et al. 2018) isdedicated to conceptual reproducibility - that is the robustness of knowledgeclaims towards verification by an alternative approach using different data,methods and procedures. The study is exploratory: it investigates only a verylimited number of publications and serves us to develop instruments foridentifying potential reproducibility issues of published studies: These are acategorization of study types and a taxonomy of threats to reproducibility. Wework with a select sample of five publications in scientometrics covering avariation of study types of theoretical, methodological, and empirical nature.Based on observations made during our exploratory review, we conclude thispaper with open questions on how to approach and assess the status of directreproducibility in scientometrics, intended for discussion at the special trackon "Reproducibility in Scientometrics" at STI2018 in Leiden.
Scheduled Sampling for Transformers.  Scheduled sampling is a technique for avoiding one of the known problems insequence-to-sequence generation: exposure bias. It consists of feeding themodel a mix of the teacher forced embeddings and the model predictions from theprevious step in training time. The technique has been used for improving themodel performance with recurrent neural networks (RNN). In the Transformermodel, unlike the RNN, the generation of a new word attends to the fullsentence generated so far, not only to the last word, and it is notstraightforward to apply the scheduled sampling technique. We propose somestructural changes to allow scheduled sampling to be applied to Transformerarchitecture, via a two-pass decoding strategy. Experiments on two languagepairs achieve performance close to a teacher-forcing baseline and show thatthis technique is promising for further exploration.
Hybrid Forests for Left Ventricle Segmentation using only the first  slice label.  Machine learning models produce state-of-the-art results in many MRI imagessegmentation. However, most of these models are trained on very large datasetswhich come from experts manual labeling. This labeling process is very timeconsuming and costs experts work. Therefore finding a way to reduce this costis on high demand. In this paper, we propose a segmentation method whichexploits MRI images sequential structure to nearly drop out this labeling task.Only the first slice needs to be manually labeled to train the model which theninfers the next slice's segmentation. Inference result is another datum used totrain the model again. The updated model then infers the third slice and thesame process is carried out until the last slice. The proposed model is ancombination of two Random Forest algorithms: the classical one and a recent onenamely Mondrian Forests. We applied our method on human left ventriclesegmentation and results are very promising. This method can also be used togenerate labels.
Artificial Neural Networks that Learn to Satisfy Logic Constraints.  Logic-based problems such as planning, theorem proving, or puzzles, typicallyinvolve combinatoric search and structured knowledge representation. Artificialneural networks are very successful statistical learners, however, for manyyears, they have been criticized for their weaknesses in representing and inprocessing complex structured knowledge which is crucial for combinatoricsearch and symbol manipulation. Two neural architectures are presented, whichcan encode structured relational knowledge in neural activation, and storebounded First Order Logic constraints in connection weights. Both architectureslearn to search for a solution that satisfies the constraints. Learning is doneby unsupervised practicing on problem instances from the same domain, in a waythat improves the network-solving speed. No teacher exists to provide answersfor the problem instances of the training and test sets. However, the domainconstraints are provided as prior knowledge to a loss function that measuresthe degree of constraint violations. Iterations of activation calculation andlearning are executed until a solution that maximally satisfies the constraintsemerges on the output units. As a test case, block-world planning problems areused to train networks that learn to plan in that domain, but the techniquesproposed could be used more generally as in integrating prior symbolicknowledge with statistical learning
A Universal Part-of-Speech Tagset.  To facilitate future research in unsupervised induction of syntacticstructure and to standardize best-practices, we propose a tagset that consistsof twelve universal part-of-speech categories. In addition to the tagset, wedevelop a mapping from 25 different treebank tagsets to this universal set. Asa result, when combined with the original treebank data, this universal tagsetand mapping produce a dataset consisting of common parts-of-speech for 22different languages. We highlight the use of this resource via two experiments,including one that reports competitive accuracies for unsupervised grammarinduction without gold standard part-of-speech tags.
Relaxing the Irrevocability Requirement for Online Graph Algorithms.  Online graph problems are considered in models where the irrevocabilityrequirement is relaxed. Motivated by practical examples where, for example,there is a cost associated with building a facility and no extra costassociated with doing it later, we consider the Late Accept model, where arequest can be accepted at a later point, but any acceptance is irrevocable.Similarly, we also consider a Late Reject model, where an accepted request canlater be rejected, but any rejection is irrevocable (this is sometimes calledpreemption). Finally, we consider the Late Accept/Reject model, where lateaccepts and rejects are both allowed, but any late reject is irrevocable. ForIndependent Set, the Late Accept/Reject model is necessary to obtain a constantcompetitive ratio, but for Vertex Cover the Late Accept model is sufficient andfor Minimum Spanning Forest the Late Reject model is sufficient. The Matchingproblem has a competitive ratio of 2, but in the Late Accept/Reject model, itscompetitive ratio is 3/2.
Entity-Duet Neural Ranking: Understanding the Role of Knowledge Graph  Semantics in Neural Information Retrieval.  This paper presents the Entity-Duet Neural Ranking Model (EDRM), whichintroduces knowledge graphs to neural search systems. EDRM represents queriesand documents by their words and entity annotations. The semantics fromknowledge graphs are integrated in the distributed representations of theirentities, while the ranking is conducted by interaction-based neural rankingnetworks. The two components are learned end-to-end, making EDRM a naturalcombination of entity-oriented search and neural information retrieval. Ourexperiments on a commercial search log demonstrate the effectiveness of EDRM.Our analyses reveal that knowledge graph semantics significantly improve thegeneralization ability of neural ranking models.
Efficient Fully Convolution Neural Network for Generating Pixel Wise  Robotic Grasps With High Resolution Images.  This paper presents an efficient neural network model to generate roboticgrasps with high resolution images. The proposed model uses fully convolutionneural network to generate robotic grasps for each pixel using 400 $\times$ 400high resolution RGB-D images. It first down-sample the images to get featuresand then up-sample those features to the original size of the input as well ascombines local and global features from different feature maps. Compared toother regression or classification methods for detecting robotic grasps, ourmethod looks more like the segmentation methods which solves the problemthrough pixel-wise ways. We use Cornell Grasp Dataset to train and evaluate themodel and get high accuracy about 94.42% for image-wise and 91.02% forobject-wise and fast prediction time about 8ms. We also demonstrate thatwithout training on the multiple objects dataset, our model can directly outputrobotic grasps candidates for different objects because of the pixel wiseimplementation.
Extended probabilistic Rand index and the adjustable moving window-based  pixel-pair sampling method.  The probabilistic Rand (PR) index has the following three problems: It lacksvariations in its value over images; the normalized probabilistic Rand (NPR)index to address this is theoretically unclear, and the sampling method ofpixel-pairs was not proposed concretely. In this paper, we propose methods forsolving these problems. First, we propose extended probabilistic Rand (EPR)index that considers not only similarity but also dissimilarity betweensegmentations. The EPR index provides twice as wide effective range as the PRindex does. Second, we propose an adjustable moving window-based pixel-pairsampling (AWPS) method in which each pixel-pair is sampled adjustably byconsidering granularities of ground truth segmentations. Results of experimentsshow that the proposed methods work effectively and efficiently.
On Orthogonality of Latin Squares.  An arrangement of s elements in s rows and s columns, such that no elementrepeats more than once in each row and each column is called a Latin square oforder s. If two Latin squares of the same order superimposed one on the otherand in the resultant array if each ordered pair occurs once and only once thenthey are called othogonal Latin Squares. A frequency square is an nxn matrix,such that each element from the list of n elements, occurs t times in each rowand in each column. These two concepts lead to a new third concept called as torthogonal latin squares, where from a set of m orthogonal Latin squares, if torthogonal Latin squares are superimposed and each ordered t tuple in theresultant array occurs once and only once then it is t othogonal Latin square.In this paper it is proposed to construct such t othogonal latin squares
Video-based Person Re-identification with Accumulative Motion Context.  Video based person re-identification plays a central role in realisticsecurity and video surveillance. In this paper we propose a novel AccumulativeMotion Context (AMOC) network for addressing this important problem, whicheffectively exploits the long-range motion context for robustly identifying thesame person under challenging conditions. Given a video sequence of the same ordifferent persons, the proposed AMOC network jointly learns appearancerepresentation and motion context from a collection of adjacent frames using atwo-stream convolutional architecture. Then AMOC accumulates clues from motioncontext by recurrent aggregation, allowing effective information flow amongadjacent frames and capturing dynamic gist of the persons. The architecture ofAMOC is end-to-end trainable and thus motion context can be adapted tocomplement appearance clues under unfavorable conditions (e.g. occlusions).Extensive experiments are conduced on three public benchmark datasets, i.e.,the iLIDS-VID, PRID-2011 and MARS datasets, to investigate the performance ofAMOC. The experimental results demonstrate that the proposed AMOC networkoutperforms state-of-the-arts for video-based re-identification significantlyand confirm the advantage of exploiting long-range motion context for videobased person re-identification, validating our motivation evidently.
Approximate Query Processing over Static Sets and Sliding Windows.  Indexing of static and dynamic sets is fundamental to a large set ofapplications such as information retrieval and caching. Denoting thecharacteristic vector of the set by B, we consider the problem of encoding setsand multisets to support approximate versions of the operations rank(i) (i.e.,computing sum_{j <= i}B[j]) and select(i) (i.e., finding min{p | rank(p) >= i})queries. We study multiple types of approximations (allowing an error in thequery or the result) and present lower bounds and succinct data structures forseveral variants of the problem. We also extend our model to sliding windows,in which we process a stream of elements and compute suffix sums. This is ageneralization of the window summation problem that allows the user to specifythe window size at query time. Here, we provide an algorithm that supportsupdates and queries in constant time while requiring just (1+o(1)) factor morespace than the fixed-window summation algorithms.
Indirect and Direct Training of Spiking Neural Networks for End-to-End  Control of a Lane-Keeping Vehicle.  Building spiking neural networks (SNNs) based on biological synapticplasticities holds a promising potential for accomplishing fast andenergy-efficient computing, which is beneficial to mobile robotic applications.However, the implementations of SNNs in robotic fields are limited due to thelack of practical training methods. In this paper, we therefore introduce bothindirect and direct end-to-end training methods of SNNs for a lane-keepingvehicle. First, we adopt a policy learned using the \textcolor{black}{DeepQ-Learning} (DQN) algorithm and then subsequently transfer it to an SNN usingsupervised learning. Second, we adopt the reward-modulatedspike-timing-dependent plasticity (R-STDP) for training SNNs directly, since itcombines the advantages of both reinforcement learning and the well-knownspike-timing-dependent plasticity (STDP). We examine the proposed approaches inthree scenarios in which a robot is controlled to keep within lane markings byusing an event-based neuromorphic vision sensor. We further demonstrate theadvantages of the R-STDP approach in terms of the lateral localization accuracyand training time steps by comparing them with other three algorithms presentedin this paper.
Learning to Count in the Crowd from Limited Labeled Data.  Recent crowd counting approaches have achieved excellent performance.However, they are essentially based on fully supervised paradigm and requirelarge number of annotated samples. Obtaining annotations is an expensive andlabour-intensive process. In this work, we focus on reducing the annotationefforts by learning to count in the crowd from limited number of labeledsamples while leveraging a large pool of unlabeled data. Specifically, wepropose a Gaussian Process-based iterative learning mechanism that involvesestimation of pseudo-ground truth for the unlabeled data, which is then used assupervision for training the network. The proposed method is shown to beeffective under the reduced data (semi-supervised) settings for severaldatasets like ShanghaiTech, UCF-QNRF, WorldExpo, UCSD, etc. Furthermore, wedemonstrate that the proposed method can be leveraged to enable the network inlearning to count from synthetic dataset while being able to generalize betterto real-world datasets (synthetic-to-real transfer).
Behavioural Analytics: Beyond Risk-based MFA.  This paper investigates how to effectively stop an attacker from usingcompromised user credentials to gain authorized entry to systems that they areotherwise not authorised to access. The proposed solution extends previous workto move beyond a risk-based multi-factor authentication system. It adds abehavioural analytics component that uses keystroke dynamics to grant or denyusers access. Given the increasing number of compromised user credentialstores, we make the assumption that criminals already know the usercredentials. Hence, to test our solution, users were given authentic usercredentials and asked to login to our proof-of-concept. Despite the fact thatall illegitimate users in our test cases were given the correct usercredentials for legitimate users, none of these were granted access by thesystem. This demonstrates zero- tolerance to false positives. The resultsdemonstrate the uniqueness of keystroke dynamics and its use to prevent userswith stolen credentials from accessing systems they are not authorized toaccess.
Asynchronous Early Output Block Carry Lookahead Adder with Improved  Quality of Results.  A new asynchronous early output block carry lookahead adder (BCLA)incorporating redundant carries is proposed. Compared to the best of existingsemi-custom asynchronous carry lookahead adders (CLAs) employingdelay-insensitive data encoding and following a 4-phase handshaking, theproposed BCLA with redundant carries achieves 13% reduction in forward latencyand 14.8% reduction in cycle time compared to the best of the existing CLAsfeaturing redundant carries with no area or power penalty. A hybrid variantinvolving a ripple carry adder (RCA) in the least significant stages i.e.BCLA-RCA is also considered that achieves a further 4% reduction in the forwardlatency and a 2.4% reduction in the cycle time compared to the proposed BCLAfeaturing redundant carries without area or power penalties.
Measuring Information Leakage in Website Fingerprinting Attacks and  Defenses.  Tor provides low-latency anonymous and uncensored network access against alocal or network adversary. Due to the design choice to minimize trafficoverhead (and increase the pool of potential users) Tor allows some informationabout the client's connections to leak. Attacks using (features extracted from)this information to infer the website a user visits are called WebsiteFingerprinting (WF) attacks. We develop a methodology and tools to measure theamount of leaked information about a website. We apply this tool to acomprehensive set of features extracted from a large set of websites and WFdefense mechanisms, allowing us to make more fine-grained observations about WFattacks and defenses.
Towards More Realistic Human-Robot Conversation: A Seq2Seq-based Body  Gesture Interaction System.  This paper presents a novel system that enables intelligent robots to exhibitrealistic body gestures while communicating with humans. The proposed systemconsists of a listening model and a speaking model used in correspondingconversational phases. Both models are adapted from the sequence-to-sequence(seq2seq) architecture to synthesize body gestures represented by the movementsof twelve upper-body keypoints. All the extracted 2D keypoints are firstly3D-transformed, then rotated and normalized to discard irrelevant information.Substantial videos of human conversations from Youtube are collected andpreprocessed to train the listening and speaking models separately, after whichthe two models are evaluated using metrics of mean squared error (MSE) andcosine similarity on the test dataset. The tuned system is implemented to drivea virtual avatar as well as Pepper, a physical humanoid robot, to demonstratethe improvement on conversational interaction abilities of our method inpractice.
Allocation of control and data channels for Large-Scale Wireless Sensor  Networks.  Both IEEE 802.15.4 and 802.15.4a standards allow for dynamic channelallocation and use of multiple channels available at their physical layers butits MAC protocols are designed only for single channel. Also, sensor'stransceivers such as CC2420 provide multiple channels and as shown in [1], [2]and [3] channel switch latency of CC2420 transceiver is just about 200$\mu$s.In order to enhance both energy efficiency and to shorten end to end delay, wepropose, in this report, a spectrum-efficient frequency allocation schemes thatare able to statically assign control channels and dynamically reuse datachannels for Personal Area Networks (PANs) inside a Large-Scale WSN based onUWB technology.
Pituitary Adenoma Volumetry with 3D Slicer.  In this study, we present pituitary adenoma volumetry using the free and opensource medical image computing platform for biomedical research: (3D) Slicer.Volumetric changes in cerebral pathologies like pituitary adenomas are acritical factor in treatment decisions by physicians and in general the volumeis acquired manually. Therefore, manual slice-by-slice segmentations inmagnetic resonance imaging (MRI) data, which have been obtained at regularintervals, are performed. In contrast to this manual time consumingslice-by-slice segmentation process Slicer is an alternative which can besignificantly faster and less user intensive. In this contribution, we comparepure manual segmentations of ten pituitary adenomas with semi-automaticsegmentations under Slicer. Thus, physicians drew the boundaries completelymanually on a slice-by-slice basis and performed a Slicer-enhanced segmentationusing the competitive region-growing based module of Slicer named GrowCut.Results showed that the time and user effort required for GrowCut-basedsegmentations were on average about thirty percent less than the pure manualsegmentations. Furthermore, we calculated the Dice Similarity Coefficient (DSC)between the manual and the Slicer-based segmentations to proof that the two arecomparable yielding an average DSC of 81.97\pm3.39%.
Utilizing Mask R-CNN for Waterline Detection in Canoe Sprint Video  Analysis.  Determining a waterline in images recorded in canoe sprint training is animportant component for the kinematic parameter analysis to assess an athlete'sperformance. Here, we propose an approach for the automated waterlinedetection. First, we utilized a pre-trained Mask R-CNN by means of transferlearning for canoe segmentation. Second, we developed a multi-stage approach toestimate a waterline from the outline of the segments. It consists of twolinear regression stages and the systematic selection of canoe parts. We thenintroduced a parameterization of the waterline as a basis for furtherevaluations. Next, we conducted a study among several experts to estimate theground truth waterlines. This not only included an average waterline drawn fromthe individual experts annotations but, more importantly, a measure for theuncertainty between individual results. Finally, we assessed our method withrespect to the question whether the predicted waterlines are in accordance withthe experts annotations. Our method demonstrated a high performance andprovides opportunities for new applications in the field of automated videoanalysis in canoe sprint.
An Importance Sampling Algorithm Based on Evidence Pre-propagation.  Precision achieved by stochastic sampling algorithms for Bayesian networkstypically deteriorates in face of extremely unlikely evidence. To address thisproblem, we propose the Evidence Pre-propagation Importance Sampling algorithm(EPIS-BN), an importance sampling algorithm that computes an approximateimportance function by the heuristic methods: loopy belief Propagation ande-cutoff. We tested the performance of e-cutoff on three large real Bayesiannetworks: ANDES, CPCS, and PATHFINDER. We observed that on each of thesenetworks the EPIS-BN algorithm gives us a considerable improvement over thecurrent state of the art algorithm, the AIS-BN algorithm. In addition, itavoids the costly learning stage of the AIS-BN algorithm.
Fooling Vision and Language Models Despite Localization and Attention  Mechanism.  Adversarial attacks are known to succeed on classifiers, but it has been anopen question whether more complex vision systems are vulnerable. In thispaper, we study adversarial examples for vision and language models, whichincorporate natural language understanding and complex structures such asattention, localization, and modular architectures. In particular, weinvestigate attacks on a dense captioning model and on two visual questionanswering (VQA) models. Our evaluation shows that we can generate adversarialexamples with a high success rate (i.e., > 90%) for these models. Our worksheds new light on understanding adversarial attacks on vision systems whichhave a language component and shows that attention, bounding box localization,and compositional internal structures are vulnerable to adversarial attacks.These observations will inform future work towards building effective defenses.
Dermoscopic Image Analysis for ISIC Challenge 2018.  This short paper reports the algorithms we used and the evaluationperformances for ISIC Challenge 2018. Our team participates in all the tasks inthis challenge. In lesion segmentation task, the pyramid scene parsing network(PSPNet) is modified to segment the lesions. In lesion attribute detectiontask, the modified PSPNet is also adopted in a multi-label way. In diseaseclassification task, the DenseNet-169 is adopted for multi-classclassification.
MicroExpNet: An Extremely Small and Fast Model For Expression  Recognition From Face Images.  This paper is aimed at creating extremely small and fast convolutional neuralnetworks (CNN) for the problem of facial expression recognition (FER) fromfrontal face images. To this end, we employed the popular knowledgedistillation (KD) method and identified two major shortcomings with its use: 1)a fine-grained grid search is needed for tuning the temperature hyperparameterand 2) to find the optimal size-accuracy balance, one needs to search for thefinal network size (or the compression rate). On the other hand, KD is provedto be useful for model compression for the FER problem, and we discovered thatits effects gets more and more significant with the decreasing model size. Inaddition, we hypothesized that translation invariance achieved usingmax-pooling layers would not be useful for the FER problem as the expressionsare sensitive to small, pixel-wise changes around the eye and the mouth.However, we have found an intriguing improvement on generalization whenmax-pooling is used. We conducted experiments on two widely-used FER datasets,CK+ and Oulu-CASIA. Our smallest model (MicroExpNet), obtained using knowledgedistillation, is less than 1MB in size and works at 1851 frames per second onan Intel i7 CPU. Despite being less accurate than the state-of-the-art,MicroExpNet still provides significant insights for designing amicroarchitecture for the FER problem.
Fast, Small and Exact: Infinite-order Language Modelling with Compressed  Suffix Trees.  Efficient methods for storing and querying are critical for scalinghigh-order n-gram language models to large corpora. We propose a language modelbased on compressed suffix trees, a representation that is highly compact andcan be easily held in memory, while supporting queries needed in computinglanguage model probabilities on-the-fly. We present several optimisations whichimprove query runtimes up to 2500x, despite only incurring a modest increase inconstruction time and memory usage. For large corpora and high Markov orders,our method is highly competitive with the state-of-the-art KenLM package. Itimposes much lower memory requirements, often by orders of magnitude, and hasruntimes that are either similar (for training) or comparable (for querying).
Shortcut Sequence Tagging.  Deep stacked RNNs are usually hard to train. Adding shortcut connectionsacross different layers is a common way to ease the training of stackednetworks. However, extra shortcuts make the recurrent step more complicated. Tosimply the stacked architecture, we propose a framework called shortcut block,which is a marriage of the gating mechanism and shortcuts, while discarding theself-connected part in LSTM cell. We present extensive empirical experimentsshowing that this design makes training easy and improves generalization. Wepropose various shortcut block topologies and compositions to explore itseffectiveness. Based on this architecture, we obtain a 6% relativelyimprovement over the state-of-the-art on CCGbank supertagging dataset. We alsoget comparable results on POS tagging task.
A Deep Reinforced Sequence-to-Set Model for Multi-Label Text  Classification.  Multi-label text classification (MLTC) aims to assign multiple labels to eachsample in the dataset. The labels usually have internal correlations. However,traditional methods tend to ignore the correlations between labels. In order tocapture the correlations between labels, the sequence-to-sequence (Seq2Seq)model views the MLTC task as a sequence generation problem, which achievesexcellent performance on this task. However, the Seq2Seq model is not suitablefor the MLTC task in essence. The reason is that it requires humans topredefine the order of the output labels, while some of the output labels inthe MLTC task are essentially an unordered set rather than an ordered sequence.This conflicts with the strict requirement of the Seq2Seq model for the labelorder. In this paper, we propose a novel sequence-to-set framework utilizingdeep reinforcement learning, which not only captures the correlations betweenlabels, but also reduces the dependence on the label order. Extensiveexperimental results show that our proposed method outperforms the competitivebaselines by a large margin.
Injecting Software Vulnerabilities with Voltage Glitching.  We show how voltage glitching can cause timing violations in CMOS behavior.Then we attack a real, security hardened, consumer device to gain codeexecution and dump the secure boot ROM.
Substate Profiling for Effective Test Suite Reduction.  Test suite reduction (TSR) aims at removing redundant test cases fromregression test suites. A typical TSR approach ensures that structural profileelements covered by the original test suite are also covered by the reducedtest suite. It is plausible that structural profiles might be unable tosegregate failing runs from passing runs, which diminishes the effectiveness ofTSR in regard to defect detection. This motivated us to explore state profiles,which are based on the collective values of program variables. This paperpresents Substate Profiling, a new form of state profiling that enhancesexisting profile-based analysis techniques such as TSR and coverage-based faultlocalization. Compared to current approaches for capturing program states,Substate Profiling is more practical and finer grained. We evaluated ourapproach using thirteen multi-fault subject programs comprising 53 defects. Ourstudy involved greedy TSR using Substate profiles and four structural profiles,namely, basic-block, branch, def-use pair, and the combination of the three.For the majority of the subjects, Substate Profiling detected considerably moredefects with a comparable level of reduction. Also, Substate profiles werefound to be complementary to structural profiles in many cases, thus, combiningboth types is beneficial.
A survey on fiber nonlinearity compensation for 400 Gbps and beyond  optical communication systems.  Optical communication systems represent the backbone of modern communicationnetworks. Since their deployment, different fiber technologies have been usedto deal with optical fiber impairments such as dispersion-shifted fibers anddispersion-compensation fibers. In recent years, thanks to the introduction ofcoherent detection based systems, fiber impairments can be mitigated usingdigital signal processing (DSP) algorithms. Coherent systems are used in thecurrent 100 Gbps wavelength-division multiplexing (WDM) standard technology.They allow the increase of spectral efficiency by using multi-level modulationformats, and are combined with DSP techniques to combat the linear fiberdistortions. In addition to linear impairments, the next generation 400 Gbps/1Tbps WDM systems are also more affected by the fiber nonlinearity due to theKerr effect. At high input power, the fiber nonlinear effects become moreimportant and their compensation is required to improve the transmissionperformance. Several approaches have been proposed to deal with the fibernonlinearity. In this paper, after a brief description of the Kerr-inducednonlinear effects, a survey on the fiber nonlinearity compensation (NLC)techniques is provided. We focus on the well-known NLC techniques and discusstheir performance, as well as their implementation and complexity. An extensionof the inter-subcarrier nonlinear interference canceler approach is alsoproposed. A performance evaluation of the well-known NLC techniques and theproposed approach is provided in the context of Nyquist and super-Nyquistsuperchannel systems.
Expected Complexity of Routing in $\Theta$ 6 and Half-$\Theta$ 6 Graphs.  We study online routing algorithms on the $\Theta$6-graph and thehalf-$\Theta$6-graph (which is equivalent to a variant of the Delaunaytriangulation). Given a source vertex s and a target vertex t in the$\Theta$6-graph (resp. half-$\Theta$6-graph), there exists a deterministiconline routing algorithm that finds a path from s to t whose length is at most2 st (resp. 2.89 st) which is optimal in the worst case [Bose et al., siam J.on Computing, 44(6)]. We propose alternative, slightly simpler routingalgorithms that are optimal in the worst case and for which we provide ananalysis of the average routing ratio for the $\Theta$6-graph andhalf-$\Theta$6-graph defined on a Poisson point process. For the$\Theta$6-graph, our online routing algorithm has an expected routing ratio of1.161 (when s and t random) and a maximum expected routing ratio of 1.22(maximum for fixed s and t where all other points are random), much better thanthe worst-case routing ratio of 2. For the half-$\Theta$6-graph, our memorylessonline routing algorithm has an expected routing ratio of 1.43 and a maximumexpected routing ratio of 1.58. Our online routing algorithm that uses aconstant amount of additional memory has an expected routing ratio of 1.34 anda maximum expected routing ratio of 1.40. The additional memory is only used toremember the coordinates of the starting point of the route. Both of thesealgorithms have an expected routing ratio that is much better than theirworst-case routing ratio of 2.89.
Multikast rutiranje open-source platformom - XORP.  Integration of a software router into embedded systems is obtainedpossibility of the most modern routers, at a much more affordable price.Transfer services TV and radio signals over the IP network are only activatedby using multicast 1 protocol for routing. Multicast routing 2 is currently afeature of only costly hardware solutions. The XORP open-source platform offersmulticast routing through a software router, with the ability to integrate intocheap embedded platforms.  ---- Integracijom softverskog rutera u embedded sisteme dobija se mogu\'cnostnajsavremenijih rutera, po znatno pristupa\v{c}nijoj ceni. Servisi prenosa TV iradio signala preko IP mre\v{z}e, za\v{z}ivljavaju tek kori\v{s}\'cenjemmultikast 1 protokola za rutiranje. Multikast rutiranje 2 je trenutno funkcijasamo skupih hardverskih re\v{s}enja. XORP open-source platforma nudi multikastrutiranje kroz softverski ruter, sa mogu\'cno\v{s}\'cu integracije u jeftineembedded platforme.
Pixel-wise Orthogonal Decomposition for Color Illumination Invariant and  Shadow-free Image.  In this paper, we propose a novel, effective and fast method to obtain acolor illumination invariant and shadow-free image from a single outdoor image.Different from state-of-the-art methods for shadow-free image that either needshadow detection or statistical learning, we set up a linear equation set foreach pixel value vector based on physically-based shadow invariants, deduce apixel-wise orthogonal decomposition for its solutions, and then get anillumination invariant vector for each pixel value vector on an image. Theillumination invariant vector is the unique particular solution of the linearequation set, which is orthogonal to its free solutions. With this illuminationinvariant vector and Lab color space, we propose an algorithm to generate ashadow-free image which well preserves the texture and color information of theoriginal image. A series of experiments on a diverse set of outdoor images andthe comparisons with the state-of-the-art methods validate our method.
FPGA Implementation of LS Code Generator for CDM Based MIMO Channel  Sounder.  MIMO (Multi Input Multi Output) wireless communication system is aninnovative solution to improve the bandwidth efficiency by exploitingmultipath-richness of the propagation environment. The degree ofmultipath-richness of the channel will determine the capacity gain attainableby MIMO deployment. Therefore, it is very important to have accurate knowledgeof the propagation environment/radio channel before MIMO implement. The radiochannel behavior can be estimated by channel measurement or channel sounding.CDM (Code Division multiplexing) is one of the channel sounding techniques thatallow accurate measurement at the cost of hardware complexity. CDM basedchannel sounder, requires code with excellent autocorrelation andcross-correlation properties which generally difficult to achievesimultaneously. Theoretical analysis and computer simulation resultdemonstrated that, having excellent correlation propertied Loosely Synchronous(LS) code sequence perform efficiently. Finally, the an efficient LS codegenerator as a data source for transmitter implemented in Xilinx FPGA that canbe integrated into CDM based 2x2 MIMO complete channel sounder.
Multi-Cue Vehicle Detection for Semantic Video Compression In  Georegistered Aerial Videos.  Detection of moving objects such as vehicles in videos acquired from anairborne camera is very useful for video analytics applications. Using fast lowpower algorithms for onboard moving object detection would also provide regionof interest-based semantic information for scene content aware imagecompression. This would enable more efficient and flexible communication linkutilization in lowbandwidth airborne cloud computing networks. Despite recentadvances in both UAV or drone platforms and imaging sensor technologies,vehicle detection from aerial video remains challenging due to small objectsizes, platform motion and camera jitter, obscurations, scene complexity anddegraded imaging conditions. This paper proposes an efficient moving vehicledetection pipeline which synergistically fuses both appearance and motion-baseddetections in a complementary manner using deep learning combined with fluxtensor spatio-temporal filtering. Our proposed multi-cue pipeline is able todetect moving vehicles with high precision and recall, while filtering outfalse positives such as parked vehicles, through intelligent fusion.Experimental results show that incorporating contextual information of movingvehicles enables high semantic compression ratios of over 100:1 with high imagefidelity, for better utilization of limited bandwidth air-to-ground networklinks.
Towards Robust Lung Segmentation in Chest Radiographs with Deep Learning.  Automated segmentation of Lungs plays a crucial role in the computer-aideddiagnosis of chest X-Ray (CXR) images. Developing an efficient Lungsegmentation model is challenging because of difficulties such as the presenceof several edges at the rib cage and clavicle, inconsistent lung shape amongdifferent individuals, and the appearance of the lung apex. In this paper, wepropose a robust model for Lung segmentation in Chest Radiographs. Our modellearns to ignore the irrelevant regions in an input Chest Radiograph whilehighlighting regions useful for lung segmentation. The proposed model isevaluated on two public chest X-Ray datasets (Montgomery County, MD, USA, andShenzhen No. 3 People's Hospital in China). The experimental result with a DICEscore of 98.6% demonstrates the robustness of our proposed lung segmentationapproach.
Large-Scale User Modeling with Recurrent Neural Networks for Music  Discovery on Multiple Time Scales.  The amount of content on online music streaming platforms is immense, andmost users only access a tiny fraction of this content. Recommender systems arethe application of choice to open up the collection to these users.Collaborative filtering has the disadvantage that it relies on explicitratings, which are often unavailable, and generally disregards the temporalnature of music consumption. On the other hand, item co-occurrence algorithms,such as the recently introduced word2vec-based recommenders, are typically leftwithout an effective user representation. In this paper, we present a newapproach to model users through recurrent neural networks by sequentiallyprocessing consumed items, represented by any type of embeddings and othercontext features. This way we obtain semantically rich user representations,which capture a user's musical taste over time. Our experimental analysis onlarge-scale user data shows that our model can be used to predict future songsa user will likely listen to, both in the short and long term.
Simple average-case lower bounds for approximate near-neighbor from  isoperimetric inequalities.  We prove an $\Omega(d/\log \frac{sw}{nd})$ lower bound for the average-casecell-probe complexity of deterministic or Las Vegas randomized algorithmssolving approximate near-neighbor (ANN) problem in $d$-dimensional Hammingspace in the cell-probe model with $w$-bit cells, using a table of size $s$.This lower bound matches the highest known worst-case cell-probe lower boundsfor any static data structure problems.  This average-case cell-probe lower bound is proved in a general frameworkwhich relates the cell-probe complexity of ANN to isoperimetric inequalities inthe underlying metric space. A tighter connection between ANN lower bounds andisoperimetric inequalities is established by a stronger richness lemma provedby cell-sampling techniques.
Stellar Resolution: Multiplicatives.  We present a new asynchronous model of computation named Stellar Resolutionbased on first-order unification. This model of computation is obtained as aformalisation of Girard's transcendental syntax programme, sketched in a seriesof three articles. As such, it is the first step towards a proper formaltreatment of Girard's proposal to tackle first-order logic in aproofs-as-program approach. After establishing formal definitions and basicproperties of stellar resolution, we explain how it generalises traditionalmodels of computation, such as logic programming and combinatorial models suchas Wang tilings. We then explain how it can represent multiplicativeproof-structures, their cut-elimination and the correctness criterion of Danosand Regnier. Further use of realisability techniques lead to dynamic semanticsfor Multiplicative Linear Logic, following previous Geometry of Interactionmodels.
Real-time optimal control via Deep Neural Networks: study on landing  problems.  Recent research on deep learning, a set of machine learning techniques ableto learn deep architectures, has shown how robotic perception and actiongreatly benefits from these techniques. In terms of spacecraft navigation andcontrol system, this suggests that deep architectures may be considered now todrive all or part of the on-board decision making system. In this paper thisclaim is investigated in more detail training deep artificial neural networksto represent the optimal control action during a pinpoint landing, assumingperfect state information. It is found to be possible to train deep networksfor this purpose and that the resulting landings, driven by the trainednetworks, are close to simulated optimal ones. These results allow for thedesign of an on-board real time optimal control system able to cope with largesets of possible initial states while still producing an optimal response.
Des correctifs de securite a la mise a jour.  The ever growing software complexity suggests that they will never be bugfreeand therefore secure. Software compagnies regulary publish updates. But maybebecause of lack of time or care or maybe because stopping application isannoying, such updates are rarely if ever deployed on users' machines. Wepropose an integrated tool allowing system administrators to deploy criticalsecurity updates on the fly on applications running remotly without end-userintervention. Our approach is based on an aspect weaving system, Arachne, thatdynamicaly rewrites binary code. Hence updated applications are still runningwhile they are updated. Our second tool Minerve integrates Arachne within thestandart updating process: Minerve takes a patch produced by dif and eventuallybuilds a dynamic patch that can later be woven to update the application on thefly. In addition, Minerve allows to consult patches translated in a dedicatedlanguage and hence eases auditing tasks.
What Should You Know Before Developing a Service Identification Approach.  In this paper, we answer a set of research questions that are required todevelop service identification approach based on the analysis of object-oriented software. Such research questions are: (1) what is a service, (2) howare services different from software components, (3) what are types ofservices, (4) what are existing service identification approaches that considerservice types into account, and (5) how to identify services based on theobject-oriented source code with respect to their types. Our methodology isbased on performing a literature review to identify the answers of theseresearch questions. Also, we propose a taxonomy of service types.
Lexicalized Stochastic Modeling of Constraint-Based Grammars using  Log-Linear Measures and EM Training.  We present a new approach to stochastic modeling of constraint-based grammarsthat is based on log-linear models and uses EM for estimation from unannotateddata. The techniques are applied to an LFG grammar for German. Evaluation on anexact match task yields 86% precision for an ambiguity rate of 5.4, and 90%precision on a subcat frame match for an ambiguity rate of 25. Experimentalcomparison to training from a parsebank shows a 10% gain from EM training.Also, a new class-based grammar lexicalization is presented, showing a 10% gainover unlexicalized models.
Predictive Linear-Gaussian Models of Stochastic Dynamical Systems.  Models of dynamical systems based on predictive state representations (PSRs)are defined strictly in terms of observable quantities, in contrast withtraditional models (such as Hidden Markov Models) that use latent variables orstatespace representations. In addition, PSRs have an effectively infinitememory, allowing them to model some systems that finite memory-based modelscannot. Thus far, PSR models have primarily been developed for domains withdiscrete observations. Here, we develop the Predictive Linear-Gaussian (PLG)model, a class of PSR models for domains with continuous observations. We showthat PLG models subsume Linear Dynamical System models (also called Kalmanfilter models or state-space models) while using fewer parameters. We alsointroduce an algorithm to estimate PLG parameters from data, and contrast itwith standard Expectation Maximization (EM) algorithms used to estimate Kalmanfilter parameters. We show that our algorithm is a consistent estimationprocedure and present preliminary empirical results suggesting that ouralgorithm outperforms EM, particularly as the model dimension increases.
Developable B-spline surface generation from control rulings.  An intuitive design method is proposed for generating developable ruledB-spline surfaces from a sequence of straight line segments indicating thesurface shape. The first and last line segments are enforced to be the head andtail ruling lines of the resulting surface while the interior lines arerequired to approximate rulings on the resulting surface as much as possible.This manner of developable surface design is conceptually similar to thepopular way of the freeform curve and surface design in the CAD community,observing that a developable ruled surface is a single parameter family ofstraight lines. This new design mode of the developable surface also providesmore flexibility than the widely employed way of developable surface designfrom two boundary curves of the surface. The problem is treated by numericaloptimization methods with which a particular level of distance error isallowed. We thus provide an effective tool for creating surfaces with a highdegree of developability when the input control rulings do not lie in exactdevelopable surfaces. We consider this ability as the superiority overanalytical methods in that it can deal with arbitrary design inputs and findpractically useful results.
Analysis of Wikipedia-based Corpora for Question Answering.  This paper gives comprehensive analyses of corpora based on Wikipedia forseveral tasks in question answering. Four recent corpora are collected,WikiQA,SelQA, SQuAD, and InfoQA, and first analyzed intrinsically by contextualsimilarities, question types, and answer categories. These corpora are thenanalyzed extrinsically by three question answering tasks, answer retrieval,selection, and triggering. An indexing-based method for the creation of asilver-standard dataset for answer retrieval using the entire Wikipedia is alsopresented. Our analysis shows the uniqueness of these corpora and suggests abetter use of them for statistical question answering learning.
'Indifference' methods for managing agent rewards.  `Indifference' refers to a class of methods used to control reward basedagents. Indifference techniques aim to achieve one or more of three distinctgoals: rewards dependent on certain events (without the agent being motivatedto manipulate the probability of those events), effective disbelief (whereagents behave as if particular events could never happen), and seamlesstransition from one reward function to another (with the agent acting as ifthis change is unanticipated). This paper presents several methods forachieving these goals in the POMDP setting, establishing their uses, strengths,and requirements. These methods of control work even when the implications ofthe agent's reward are otherwise not fully understood.
Process Symmetry in Probabilistic Transducers.  Model checking is the process of deciding whether a system satisfies a givenspecification. Often, when the setting comprises multiple processes, thespecifications are over sets of input and output signals that correspond toindividual processes. Then, many of the properties one wishes to specify aresymmetric with respect to the processes identities. In this work, we considerthe problem of deciding whether the given system exhibits symmetry with respectto the processes' identities. When the system is symmetric, this gives insightinto the behaviour of the system, as well as allows the designer to use onlyrepresentative specifications, instead of iterating over all possible processidentities.  Specifically, we consider probabilistic systems, and we propose severalvariants of symmetry. We start with precise symmetry, in which, given apermutation $\pi$, the system maintains the exact distribution of permutedoutputs, given a permuted inputs. We proceed to study approximate versions ofsymmetry, including symmetry induced by small $L_\infty$ norm, variants ofParikh-image based symmetry, and qualitative symmetry. For each type ofsymmetry, we consider the problem of deciding whether a given system exhibitsthis type of symmetry.
A promise checked is a promise kept: Inspection Testing.  Occasionally, developers need to ensure that the compiler treats their codein a specific way that is only visible by inspecting intermediate or finalcompilation artifacts. This is particularly common with carefully craftedcompositional libraries, where certain usage patterns are expected to triggeran intricate sequence of compiler optimizations -- stream fusion is awell-known example.  The developer of such a library has to manually inspect build artifacts andcheck for the expected properties. Because this is too tedious to do often, itwill likely go unnoticed if the property is broken by a change to the librarycode, its dependencies or the compiler. The lack of automation has led toreleased versions of such libraries breaking their documented promises.  This indicates that there is an unrecognized need for a new testing paradigm,inspection testing, where the programmer declaratively describes non-functionalproperties of an compilation artifact and the compiler checks these properties.We define inspection testing abstractly, implement it in the context of Haskelland show that it increases the quality of such libraries.
SNS Timing System.  This poster describes the timing system being designed for Spallation NeutronSource being built at Oak Ridge National lab.
Learning Hybrid Object Kinematics for Efficient Hierarchical Planning  Under Uncertainty.  Sudden changes in the dynamics of robotic tasks, such as contact with anobject or the latching of a door, are often viewed as inconvenientdiscontinuities that make manipulation difficult. However, when thesetransitions are well-understood, they can be leveraged to reduce uncertainty oraid manipulation---for example, wiggling a screw to determine if it is fullyinserted or not. Current model-free reinforcement learning approaches requirelarge amounts of data to learn to leverage such dynamics, scale poorly asproblem complexity grows, and do not transfer well to significantly differentproblems. By contrast, hierarchical POMDP planning-based methods scale well viaplan decomposition, work well on novel problems, and directly consideruncertainty, but often rely on precise hand-specified models and taskdecompositions. To combine the advantages of these opposing paradigms, wepropose a new method, MICAH, which given unsegmented data of an object's motionunder applied actions, (1) detects changepoints in the object motion modelusing action-conditional inference, (2) estimates the individual local motionmodels with their parameters, and (3) converts them into a hybrid automatonthat is compatible with hierarchical POMDP planning. We show that modellearning under MICAH is more accurate and robust to noise than priorapproaches. Further, we combine MICAH with a hierarchical POMDP planner todemonstrate that the learned models are rich enough to be used for performingmanipulation tasks under uncertainty that require the objects to be used innovel ways not encountered during training.
There is Something Beyond the Twitter Network.  How information spreads through a social network? Can we assume, that theinformation is spread only through a given social network graph? What is thecorrect way to compare the models of information flow? These are the basicquestions we address in this work.  We focus on meticulous comparison of various, well-known models of rumorpropagation in the social network. We introduce the model incorporating massmedia and effects of absent nodes. In this model the information appearsspontaneously in the graph. Using the most conservative metric, we showed thatthe distribution of cascades sizes generated by this model fits the real datamuch better than the previously considered models.
Analysis and Modeling of Traffic in Modern Data Communication Networks.  In performance analysis and design of communication netword modeling datatraffic is important. With introduction of new applications, thecharacteristics of the data traffic changes. We present a brief review thedifferent models of data traffic and how they have evolved. We present resultsof data traffic analysis and simulated traffic, which demonstrates that thepacket train model fits the traffic at source destination level and long-memory(self-similar) model fits the traffic at the aggregate level.
NFCGate: Opening the Door for NFC Security Research with a  Smartphone-Based Toolkit.  Near-Field Communication (NFC) is being used in a variety ofsecurity-critical applications, from access control to payment systems.However, NFC protocol analysis typically requires expensive or conspicuousdedicated hardware, or is severely limited on smartphones. In 2015, the NFCGateproof of concept aimed at solving this issue by providing capabilities for NFCanalysis employing off-the-shelf Android smartphones.  In this paper, we present an extended and improved NFC toolkit based on thefunctionally limited original open-source codebase. With in-flight trafficanalysis and modification, relay, and replay features this toolkit turns anoff-the-shelf smartphone into a powerful NFC research tool. To support thedevelopment of countermeasures against relay attacks, we investigate thelatency incurred by NFCGate in different configurations.  Our newly implemented features and improvements enable the case study of anaward-winning, enterprise-level NFC lock from a well-known European lockvendor, which would otherwise require dedicated hardware. The analysis of thelock reveals several security issues, which were disclosed to the vendor.
Statistical Model Checking : An Overview.  Quantitative properties of stochastic systems are usually specified in logicsthat allow one to compare the measure of executions satisfying certain temporalproperties with thresholds. The model checking problem for stochastic systemswith respect to such logics is typically solved by a numerical approach thatiteratively computes (or approximates) the exact measure of paths satisfyingrelevant subformulas; the algorithms themselves depend on the class of systemsbeing analyzed as well as the logic used for specifying the properties. Anotherapproach to solve the model checking problem is to \emph{simulate} the systemfor finitely many runs, and use \emph{hypothesis testing} to infer whether thesamples provide a \emph{statistical} evidence for the satisfaction or violationof the specification. In this short paper, we survey the statistical approach,and outline its main advantages in terms of efficiency, uniformity, andsimplicity.
Output Feedback Controller Design with Symbolic Observers for  Cyber-physical Systems.  In this paper, we design a symbolic output feedback controller of acyber-physical system (CPS). The physical plant is modeled by an infinitetransition system. We consider the situation that a finite abstracted system ofthe physical plant, called a c-abstracted system, is given. There exists anapproximate alternating simulation relation from the c-abstracted system to thephysical plant. A desired behavior of the c-abstracted system is also given,and we have a symbolic state feedback controller of the physical plant. Weconsider the case where some states of the plant are not measured. Then, toestimate the states with abstracted outputs measured by sensors, we introduce afinite abstracted system of the physical plant, called an o-abstracted system,such that there exists an approximate simulation relation. The relationguarantees that an observer designed based on the state of the o-abstractedsystem estimates the current state of the plant. We construct a symbolic outputfeedback controller by composing these systems. By a relation-based approach,we proved that the controlled system approximately exhibits the desiredbehavior.
Using Syntactic Features for Phishing Detection.  This paper reports on the comparison of the subject and object of verbs intheir usage between phishing emails and legitimate emails. The purpose of thisresearch is to explore whether the syntactic structures and subjects andobjects of verbs can be distinguishable features for phishing detection. Toachieve the objective, we have conducted two series of experiments: thesyntactic similarity for sentences, and the subject and object of verbcomparison. The results of the experiments indicated that both features can beused for some verbs, but more work has to be done for others.
Nonlinear System Identification and Behavioral Modeling.  This paper has been withdrawn by the author
Talking about interaction*.  Recent research has exposed disagreements over the nature and usefulness ofwhat may (or may not) be Human-Computer Interaction's fundamental phenomenon:'interaction'. For some, HCI's theorising about interaction has been deficient,impacting its capacity to inform decisions in design, suggesting the needeither to perform first-principles definition work or broader administrativeclarification and formalisation of the multitude of formulations of theconcepts of interaction and their particular uses. For others, there remainopen questions over the continued relevance of certain 'versions' ofinteraction as a useful concept in HCI at all. We pursue a differentperspective in this paper, reviewing how HCI treats interaction throughexamining its 'conceptual pragmatics' within HCI's discourse. We argue thatarticulations of the concepts of interaction can be a site of productiveconflict for HCI that for many reasons may resist attempts of formalisation aswell as attempts to dispense with them. The main contribution of this paper isin specifying how we might go about talking of interaction and the value ofinteraction language as promiscuous concepts.
Industrial robot ransomware: Akerbeltz.  Cybersecurity lessons have not been learnt from the dawn of othertechnological industries. In robotics, the existing insecurity landscape needsto be addressed immediately. Several manufacturers profiting from the lack ofgeneral awareness are systematically ignoring their responsibilities byclaiming their insecure (open) systems facilitate system integration,disregarding the safety, privacy and ethical consequences that their (lack of)actions have. In an attempt to raise awareness and illustrate the "insecurityby design in robotics" we have created Akerbeltz, the first known instance ofindustrial robot ransomware. Our malware is demonstrated using a leading brandfor industrial collaborative robots, Universal Robots. We describe therationale behind our target and discuss the general flow of the attackincluding the initial cyber-intrusion, lateral movement and later controlphase. We urge security researchers to adopt some sort of disclosure policythat forces manufacturers to react promptly. We advocate against security byobscurity and encourage the release of similar actions once vulnerabilityreports fall into a dead-end. Actions are now to be taken to abide a futurefree of zero-days for robotics.
Visualizing Class Information.  A class is used in object oriented programming to describe each object in thesystem. It is as a template contains the methods and attributes for eachobject. The volume of information within the class has a role in the timerequired for its implementation, testing and understanding the class.Developers are dealing with large projects that contain a large number of LinesOf Code (LOC). So that, extracting information about the classes requires timeand big effort from the developers. To solve this problem, we present avisualization approach to display class information for developers. Our methodassumed each class is a cone chart and each cone represents one of the classmetrics that include number of methods, attributes and the number of Lines OfCode (LOC). The height of each cone indicates the total number of methods,attributes and number of Lines Of Code (LOC) which found in a class. Also, eachcone has a different color from the other to facilitate the distinction amongthem
An informative path planning framework for UAV-based terrain monitoring.  Unmanned Aerial Vehicles (UAVs) represent a new frontier in a wide range ofmonitoring and research applications. To fully leverage their potential, a keychallenge is planning missions for efficient data acquisition in complexenvironments. To address this issue, this article introduces a generalInformative Path Planning (IPP) framework for monitoring scenarios using anaerial robot, focusing on problems in which the value of sensor information isunevenly distributed in a target area and unknown a priori . The approach iscapable of learning and focusing on regions of interest via adaptation to mapeither discrete or continuous variables on the terrain usingvariable-resolution data received from probabilistic sensors. During a mission,the terrain maps built online are used to plan information-rich trajectories incontinuous 3-D space by optimizing initial solutions obtained by a coarse gridsearch. Extensive simulations show that our approach is more efficient thanexisting methods. We also demonstrate its real-time application on aphotorealistic mapping scenario using a publicly available dataset anddemonstrate a proof of concept for an agricultural monitoring task.
Eat & Tell: A Randomized Trial of Random-Loss Incentive to Increase  Dietary Self-Tracking Compliance.  A growing body of evidence has shown that incorporating behavioral economicsprinciples into the design of financial incentive programs helps improve theircost-effectiveness, promote individuals' short-term engagement, and increasecompliance in health behavior interventions. Yet, their effects on long-termengagement have not been fully examined. In study designs where repeatedadministration of incentives is required to ensure the regularity of behaviors,the effectiveness of subsequent incentives may decrease as a result of the lawof diminishing marginal utility. In this paper, we introduce random-lossincentive -- a new financial incentive based on loss aversion andunpredictability principles -- to address the problem of individuals' growinginsensitivity to repeated interventions over time. We evaluate the newincentive design by conducting a randomized controlled trial to measure theinfluences of random losses on participants' dietary self-tracking andself-reporting compliance using a mobile web application called Eat & Tell. Theresults show that random losses are significantly more effective than fixedlosses in encouraging long-term engagement.
Immuno-inspired robotic applications: a review.  Artificial immune systems primarily mimic the adaptive nature of biologicalimmune functions. Their ability to adapt to varying pathogens makes suchsystems a suitable choice for various robotic applications. Generally,AIS-based robotic applications map local instantaneous sensory information intoeither an antigen or a co-stimulatory signal, according to the choice ofrepresentation schema. Algorithms then use relevant immune functions to outputeither evolved antibodies or maturity of dendritic cells, in terms of actuationsignals. It is observed that researchers, in an attempt to solve the problem inhand, do not try to replicate the biological immunity but select necessaryimmune functions instead, resulting in an ad-hoc manner these applications arereported. Authors, therefore, present a comprehensive review of immuno-inspiredrobotic applications in an attempt to categorize them according to underlyingimmune definitions. Implementation details are tabulated in terms ofcorresponding mathematical expressions and their representation schema thatinclude binary, real or hybrid data. Limitations of reported applications arealso identified in light of modern immunological interpretations. As a resultof this study, authors suggest a renewed focus on innate immunity and alsoemphasize that immunological representations should benefit from robotembodiment and must be extended to include modern trends.
Proceedings of the Sixth Conference on Uncertainty in Artificial  Intelligence (1990).  This is the Proceedings of the Sixth Conference on Uncertainty in ArtificialIntelligence, which was held in Cambridge, MA, Jul 27 - Jul 29, 1990
A Case for a Global Information Network.  This paper argues for the adoption of a information centric system modelinstead of the current service-oriented one. We present an architecture for aglobal information storage and dissemination network which provides forefficient interaction and coordination among autonomous actors through a sharedinformation space. We believe that the resulting, loosely coupled systems,while probabilistic in nature, will lead to robust outcomes at large scales.
Instance Segmentation with Point Supervision.  Instance segmentation methods often require costly per-pixel labels. Wepropose a method that only requires point-level annotations. During training,the model only has access to a single pixel label per object, yet the task isto output full segmentation masks. To address this challenge, we construct anetwork with two branches: (1) a localization network (L-Net) that predicts thelocation of each object; and (2) an embedding network (E-Net) that learns anembedding space where pixels of the same object are close. The segmentationmasks for the located objects are obtained by grouping pixels with similarembeddings. At training time, while L-Net only requires point-levelannotations, E-Net uses pseudo-labels generated by a class-agnostic objectproposal method. We evaluate our approach on PASCAL VOC, COCO, KITTI andCityScapes datasets. The experiments show that our method (1) obtainscompetitive results compared to fully-supervised methods in certain scenarios;(2) outperforms fully- and weakly- supervised methods with a fixed annotationbudget; and (3) is a first strong baseline for instance segmentation withpoint-level supervision.
A Closer Look at Data Bias in Neural Extractive Summarization Models.  In this paper, we take stock of the current state of summarization datasetsand explore how different factors of datasets influence the generalizationbehaviour of neural extractive summarization models. Specifically, we firstpropose several properties of datasets, which matter for the generalization ofsummarization models. Then we build the connection between priors residing indatasets and model designs, analyzing how different properties of datasetsinfluence the choices of model structure design and training methods. Finally,by taking a typical dataset as an example, we rethink the process of the modeldesign based on the experience of the above analysis. We demonstrate that whenwe have a deep understanding of the characteristics of datasets, a simpleapproach can bring significant improvements to the existing state-of-the-artmodel.A
Sense Beyond Expressions: Cuteness.  With the development of Internet culture, cuteness has become a popularconcept. Many people are curious about what factors making a person look cute.However, there is rare research to answer this interesting question. In thiswork, we construct a dataset of personal images with comprehensively annotatedcuteness scores and facial attributes to investigate this high-level concept indepth. Based on this dataset, through an automatic attributes mining process,we find several critical attributes determining the cuteness of a person. Wealso develop a novel Continuous Latent Support Vector Machine (C-LSVM) methodto predict the cuteness score of one person given only his image. Extensiveevaluations validate the effectiveness of the proposed method for cutenessprediction.
DroNet: Efficient convolutional neural network detector for real-time  UAV applications.  Unmanned Aerial Vehicles (drones) are emerging as a promising technology forboth environmental and infrastructure monitoring, with broad use in a plethoraof applications. Many such applications require the use of computer visionalgorithms in order to analyse the information captured from an on-boardcamera. Such applications include detecting vehicles for emergency response andtraffic monitoring. This paper therefore, explores the trade-offs involved inthe development of a single-shot object detector based on deep convolutionalneural networks (CNNs) that can enable UAVs to perform vehicle detection undera resource constrained environment such as in a UAV. The paper presents aholistic approach for designing such systems; the data collection and trainingstages, the CNN architecture, and the optimizations necessary to efficientlymap such a CNN on a lightweight embedded processing platform suitable fordeployment on UAVs. Through the analysis we propose a CNN architecture that iscapable of detecting vehicles from aerial UAV images and can operate between5-18 frames-per-second for a variety of platforms with an overall accuracy of~95%. Overall, the proposed architecture is suitable for UAV applications,utilizing low-power embedded processors that can be deployed on commercialUAVs.
A Telecom Perspective on the Internet of Drones: From LTE-Advanced to 5G.  Drones are driving numerous and evolving use cases, and creatingtransformative socio-economic benefits. Drone operation needs wirelessconnectivity for communication between drones and ground control systems, amongdrones, and between drones and air traffic management systems. Mobile networksare well positioned to identify, track, and control the growing fleet ofdrones. The wide-area, quality, and secure connectivity provided by mobilenetworks can enhance the efficiency and effectiveness of drone operationsbeyond visual line-of-sight range. In this article, we elaborate how the droneecosystem can benefit from mobile technologies, summarize key capabilitiesrequired by drone applications, and analyze the service requirements on mobilenetworks. We present field trial results collected in LTE-Advanced networks togain insights into the capabilities of the current 4G+ networks for connecteddrones and share our vision on how 5G networks can further support diversifieddrone applications.
On the influence of intelligence in (social) intelligence testing  environments.  This paper analyses the influence of including agents of different degrees ofintelligence in a multiagent system. The goal is to better understand how wecan develop intelligence tests that can evaluate social intelligence. Weanalyse several reinforcement algorithms in several contexts of cooperation andcompetition. Our experimental setting is inspired by the recently developedDarwin-Wallace distribution.
Autonomy with regard to an Attribute.  This paper presents a model of autonomy called autonomy with regard to anattribute applicable to cognitive and not cognitive artificial agents. Threecriteria (global / partial, social / nonsocial, absolute / relative) aredefined and used to describe the main characteristics of this type of autonomy.A software agent autonomous with regard to the mobility illustrates a possibleimplementation of this model.
Leveraging the Power of Gabor Phase for Face Identification: A Block  Matching Approach.  Different from face verification, face identification is much more demanding.To reach comparable performance, an identifier needs to be roughly N timesbetter than a verifier. To expect a breakthrough in face identification, weneed a fresh look at the fundamental building blocks of face recognition. Inthis paper we focus on the selection of a suitable signal representation andbetter matching strategy for face identification. We demonstrate how Gaborphase could be leveraged to improve the performance of face identification byusing the Block Matching method. Compared to the existing approaches, theproposed method features much lower algorithmic complexity: face images areonly filtered by a single-scale Gabor filter pair and the matching is performedbetween any pairs of face images at hand without involving any trainingprocess. Benchmark evaluations show that the proposed approach is totallycomparable to and even better than state-of-the-art algorithms, which aretypically based on more features extracted from a large set of Gabor facesand/or rely on heavy training processes.
Efficiency and Nash Equilibria in a Scrip System for P2P Networks.  A model of providing service in a P2P network is analyzed. It is shown thatby adding a scrip system, a mechanism that admits a reasonable Nash equilibriumthat reduces free riding can be obtained. The effect of varying the totalamount of money (scrip) in the system on efficiency (i.e., social welfare) isanalyzed, and it is shown that by maintaining the appropriate ratio between thetotal amount of money and the number of agents, efficiency is maximized. Thework has implications for many online systems, not only P2P networks but also awide variety of online forums for which scrip systems are popular, but formalanalyses have been lacking.
Runtime Fault Detection in Programmed Molecular Systems.  Watchdog timers are devices that are commonly used to monitor the health ofsafety-critical hardware and software systems. Their primary function is toraise an alarm if the monitored systems fail to emit periodic "heartbeats" thatsignal their well-being. In this paper we design and verify a molecularwatchdog timer for monitoring the health of programmed molecular nanosystems.This raises new challenges because our molecular watchdog timer and the systemthat it monitors both operate in the probabilistic environment of chemicalkinetics, where many failures are certain to occur and it is especially hard todetect the absence of a signal.  Our molecular watchdog timer is the result of an incremental design processthat uses goal-oriented requirements engineering, simulation, stochasticanalysis, and software verification tools. We demonstrate the molecularwatchdog's functionality by having it monitor a molecular oscillator. Both themolecular watchdog timer and the oscillator are implemented as chemicalreaction networks, which are the current programming language of choice formany molecular programming applications.
Parametric updates in parametric timed automata.  We introduce a new class of Parametric Timed Automata (PTAs) where we allowclocks to be compared to parameters in guards, as in classic PTAs, but also tobe updated to parameters. We focus here on the EF-emptiness problem: "is theset of parameter valuations for which some given location is reachable in theinstantiated timed automaton empty?". This problem is well-known to beundecidable for PTAs, and so it is for our extension. Nonetheless, if we updateall clocks each time we compare a clock with a parameter and each time weupdate a clock to a parameter, we obtain a syntactic subclass for which we candecide the EF-emptiness problem and even perform the exact synthesis of the setof rational valuations such that a given location is reachable. To the best ofour knowledge, this is the first non-trivial subclass of PTAs, actually evenextended with parametric updates, for which this is possible.
